<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Pentesting_Procedure</title>
</head><body>Primary Process - 4 steps<br/>
&nbsp;--&gt; Reconnaissance --&gt; Mapping --&gt; Vulnerability Discovery --&gt; Exploitation<br/>
<ul><li>Reconnaissance</li>
<li>Mapping</li>
<li style="list-style-type: none"><ul><li>Mainly performed by scraping crawlers.</li>
<li>Crawling</li>
<li style="list-style-type: none"><ul><li>Request the first page</li>
<li>Pass all the content back</li>
<li>Extract all the links</li>
<li style="list-style-type: none"><ul><li>Then repeat those processes on the gather links as well.</li>
</ul>
</li>
</ul>
</li>
<li>Not everthing may be picked up by a crawler, so we can go back with an HTTP proxy and gather what was missed.</li>
<li>A Crawler does not usually interpret JavaScript, so any links/info generated with JS will be missed.</li>
<li>&nbsp;</li>
</ul>
</li>
<li>Vulnerability Discovery</li>
<li>Exploitation</li>
</ul>
</body></html>